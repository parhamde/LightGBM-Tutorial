# LightGBM-Tutorial
In this project, I will discuss one of the most successful ML algorithm LightGBM Classifier. LightGBM is a fast, distributed, high performance gradient boosting framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks. It has helped Kagglers win data science competitions. 


So, let's get started.

## **Table of Contents** 

- 1.	Introduction to LightGBM
- 2.	LightGBM intuition
   - 2.1	Leaf-wise tree growth
   - 2.2	Level-wise tree growth
   - 2.3	Important points about tree-growth
- 3.	XGBoost Vs LightGBM
- 4.	LightGBM Parameters
   - 4.1	Control Parameters
   - 4.2	Core Parameters
   - 4.3	Metric Parameter
   - 4.4	IO Parameter
- 5.	LightGBM implementation in Python
   - 5.1	Load packages
   - 5.2	Read dataset
   - 5.3	Preview dataset
   - 5.4	Summary of dataset
   - 5.5	Check the distribution of target variable
   - 5.6	Declare feature vector and target variable
   - 5.7	Split data into training and test set
   - 5.8	LightGBM model development and training
   - 5.9	Model prediction
   - 5.10	Model accuracy
   - 5.11	Compare train and test set accuracy
   - 5.12	Check for overfitting
   - 5.13	Confusion-matrix
   - 5.14	Classification-metrices
- 6.	Results and conclusion
- 7.	LightGBM parameter tuning
   - 7.1	For faster speed
   - 7.2	For better accuracy
   - 7.3	To deal with over-fitting
- 8.	References